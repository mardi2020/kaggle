# sample_submission ê³¼ result ëŒ€ì¡° í™•ì¸

import pandas as pd
from sklearn.metrics import (
    accuracy_score,
    f1_score,
    precision_score,
    recall_score,
    confusion_matrix,
    classification_report
)

from twitter_disaster.util.load_files import get_latest_file
from twitter_disaster.paramters import BASE_DIR


def final_report():
    true_labels = pd.read_csv(BASE_DIR / 'data/input/sample_submission.csv')
    predicted_labels = pd.read_csv(get_latest_file('submission'))

    true_labels = true_labels.sort_values("id").reset_index(drop=True)
    predicted_labels = predicted_labels.sort_values("id").reset_index(drop=True)

    # âœ… ì •ë‹µ ë°ì´í„°ì™€ ì˜ˆì¸¡ ë¹„êµ
    y_true = true_labels["target"].values
    y_pred = predicted_labels["target"].values

    # âœ… ì •í™•ë„, F1 Score ë“± í‰ê°€
    accuracy = accuracy_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred)
    recall = recall_score(y_true, y_pred)

    # âœ… ì¶œë ¥
    print(f"ğŸ”¹ Accuracy: {accuracy:.4f}")
    print(f"ğŸ”¹ F1 Score: {f1:.4f}")
    print(f"ğŸ”¹ Precision: {precision:.4f}")
    print(f"ğŸ”¹ Recall: {recall:.4f}")

    # âœ… Confusion Matrix ì¶œë ¥
    print("\nConfusion Matrix:")
    print(confusion_matrix(y_true, y_pred))

    # âœ… ìƒì„¸ ë¦¬í¬íŠ¸ ì¶œë ¥
    print("\nClassification Report:")
    print(classification_report(y_true, y_pred))
